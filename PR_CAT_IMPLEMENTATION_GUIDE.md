# PR Cat Implementation Guide

## Overview
This document outlines the implementation plan for the PR Cat application - an AI-powered GitHub PR categorization and analytics tool. The application uses Next.js for both frontend and backend, Turso for database (including vector capabilities), and integrates with GitHub and AI services.

## Technology Stack
- **Framework**: Next.js 14+ with App Router
- **Database**: Turso DB (SQL + vector capabilities)
- **Authentication**: NextAuth with GitHub provider
- **Styling**: Tailwind CSS with shadcn/ui components
- **Data Fetching**: GitHub API, Octokit
- **AI Integration**: OpenAI API or similar
- **Deployment**: Vercel

## Implementation Status

### âœ… Completed Work

#### Project Setup & Configuration
- âœ… Initialize Next.js project with TypeScript
- âœ… Set up Tailwind CSS and shadcn/ui
- âœ… Configure ESLint and Prettier
- âœ… Create initial project structure (app directory layout)
- âœ… Add environment variable templates (.env.example)

#### Authentication System
- âœ… Install and configure NextAuth.js
- âœ… Set up GitHub OAuth provider
- âœ… Create login/signup pages
- âœ… Implement session handling
- âœ… Add protected route middleware

#### User Interface Implementation
- âœ… Dashboard page UI
- âœ… Settings page UI
- âœ… Lifecycle view UI
- âœ… Analytics view UI
- âœ… Team view UI
- âœ… Repository insights components
- âœ… PR quality details components
- âœ… Engineering metrics components
- âœ… GitHub organization and repository selection components
- âœ… Responsive layouts and component design

#### Database Setup
- âœ… Set up Turso database account
- âœ… Configure direct SQL connection to Turso
- âœ… Create initial schema with necessary tables:
  - users
  - organizations
  - repositories
  - pull_requests
  - categories
  - recommendations
  - settings
- âœ… Set up migration system (schema_migrations table present)
- âœ… Enable vector extension in Turso (schema prepared with embeddings table)

#### GitHub Integration
- âœ… OAuth setup with GitHub provider
- âœ… Basic API access implementation
- âœ… Repository data fetching
- âœ… Organization data fetching
- âœ… Implementation of repository repositories
- âœ… Implementation of organization repositories
- âœ… Webhook endpoint implementation
- âœ… PR event processing via webhooks
- âœ… PR review event processing via webhooks
- âœ… Installation event processing for GitHub App
- âœ… Webhook configuration UI

#### Data Processing
- âœ… Pull request data collection and processing
- âœ… PR review data collection and processing
- âœ… Multi-provider AI integration (OpenAI, Google, Anthropic)
- âœ… PR categorization using AI

### ðŸ”„ Work In Progress

#### GitHub Integration Completion
- âš ï¸ Background processing for large-scale repository analysis
- âš ï¸ PR comment analysis and statistics

#### Data Processing Enhancement
- âš ï¸ Implementation of notifications for PR events
- âš ï¸ Historical PR data analysis for repositories
- âš ï¸ Batch processing improvements for large repositories

#### AI Processing Pipeline Enhancement
- âš ï¸ Improve vector embedding generation
- âš ï¸ Implement semantic search using embeddings
- âš ï¸ Enhance categorization confidence scoring
- âš ï¸ Add caching layer for processed results

#### Dashboard Data Integration
- âš ï¸ Connect dashboard metrics to real-time data
- âš ï¸ Implement dashboard statistics refreshing
- âš ï¸ Add PR activity timeline with real data
- âš ï¸ Display actionable recommendations based on analysis

#### Analytics View Integration
- âš ï¸ Connect analytics visualizations to real data
- âš ï¸ Implement data filtering and aggregation
- âš ï¸ Create trend analysis views
- âš ï¸ Add custom report generation

## Next Implementation Steps

Based on the current state of the project, the following should be the next implementation priorities:

### Phase 1: Dashboard Data Integration

#### 1.1 Metrics Integration
```
- Connect repository metrics components to real database data
- Implement PR count by category charts
- Add PR size distribution metrics
- Create PR review time metrics
- Implement PR state distribution charts
```

#### 1.2 Activity Timeline
```
- Build real-time PR activity feed
- Add filtering by repository and category
- Implement PR state indicators
- Create interactive timeline UI
```

#### 1.3 Investment Area Distribution
```
- Connect category distribution components to real data
- Create time-based trend analysis
- Add repository filtering for category distribution
- Implement interactive category selection
```

### Phase 2: Analytics Enhancement

#### 2.1 PR Quality Metrics
```
- Calculate and display PR size metrics
- Implement review coverage analysis
- Add change request statistics
- Create PR lifecycle duration metrics
```

#### 2.2 Repository Insights
```
- Add repository activity heatmaps
- Implement contributor statistics
- Create repository comparison views
- Add PR volume trend analysis
```

#### 2.3 Category Analytics
```
- Implement category distribution over time
- Add category confidence analysis
- Create category-based repository comparisons
- Implement category suggestion improvements
```

### Phase 3: Recommendation Engine

#### 3.1 Pattern Detection
```
- Analyze PR size patterns across repositories
- Implement review bottleneck detection
- Add inactive repository identification
- Create workflow improvement suggestions
```

#### 3.2 Actionable Recommendations
```
- Generate specific actionable recommendations
- Implement recommendation prioritization
- Add recommendation tracking
- Create recommendation effectiveness metrics
```

#### 3.3 Team Insights
```
- Implement team member contribution analysis
- Add review load distribution metrics
- Create PR quality by author analysis
- Implement team collaboration metrics
```

## Implementation Roadmap

### Phase 1: Core Data Infrastructure

#### 1.1 Database Implementation
```
- Set up Turso database using Platform API
- Create database groups for development and production
- Generate authentication tokens for database access
- Implement direct SQL queries using Turso's HTTP API
- Create SQL migration scripts for schema management
- Configure SQLite extensions for vector support
- Set up connection pooling for performance
- Implement database access layer with prepared statements
```

#### 1.2 Complete GitHub Integration
```
- Extend GitHub API client wrapper
- Complete repository selection interface
- Implement organization access controls
- Set up webhook receiver for real-time updates
- Configure webhook security and validation
- Create webhook management UI
```

### Phase 2: Core Data Processing

#### 2.1 GitHub Data Collection
```
- Build PR fetching service
- Implement pagination for large repositories
- Create functions to extract PR metadata
- Add code to process PR comments and reviews
- Set up hooks for PR state changes
- Implement data normalization
```

#### 2.2 AI Processing Pipeline
```
- Create text extraction system for PRs
- Build prompt templates for AI categorization
- Implement vector embedding generation
- Create categorization confidence scoring
- Set up batch processing for historical PRs
- Add caching layer for processed results
```

#### 2.3 Background Processing
```
- Set up Vercel Cron jobs
- Create job queue for PR processing
- Implement webhook handling for real-time events
- Add status tracking for long-running jobs
- Create retry mechanism for failed requests
```

### Phase 3: Connect UI to Data Layer

#### 3.1 Dashboard Data Integration
```
- Connect dashboard metrics to real data
- Implement real-time data updates
- Add loading states for asynchronous operations
- Create error handling for API failures
- Implement data refresh mechanisms
```

#### 3.2 Analytics Data Integration
```
- Connect analytics visualizations to real data
- Implement data filtering and aggregation
- Create export functionality
- Add custom report generation
- Implement data caching for performance
```

#### 3.3 Team View Data Integration
```
- Connect team metrics to real data
- Implement developer comparison functionality
- Add PR quality assessment
- Create review distribution visualization
- Implement workload analysis
```

### Phase 4: Advanced Features

#### 4.1 Recommendations Engine
```
- Implement pattern detection for workflow issues
- Create AI-powered recommendation generator
- Build recommendation tracking system
- Add success metrics calculations
- Implement priority scoring for recommendations
```

#### 4.2 Search and Filtering
```
- Create global search functionality
- Implement advanced PR filtering
- Add saved search functionality
- Build semantic search using vector embeddings
- Create custom filter builder
```

#### 4.3 Notifications System
```
- Implement in-app notifications
- Add email notification options
- Create alert rules configuration
- Build digest reports
- Implement notification preferences
```

### Phase 5: Deployment & Refinement

#### 5.1 Testing & Quality Assurance
```
- Write unit tests for core components
- Implement integration tests for data flow
- Add end-to-end tests for critical paths
- Validate GitHub API usage efficiency
- Test performance with large data sets
```

#### 5.2 UI Polish & Optimization
```
- Add skeleton loading states
- Implement error boundaries
- Optimize component rendering
- Add animations and transitions
- Improve overall user experience
```

#### 5.3 Deployment
```
- Configure Vercel production environment
- Set up monitoring and logging
- Create user documentation
- Implement usage analytics
- Configure proper error reporting
```

### Architecture Improvements

#### Centralized Repository Access

To ensure consistent access patterns and prevent code duplication, the repository access logic has been centralized:

1. **Repository Service**
   - Created a centralized `RepositoryService` class with static methods
   - Implements organization-based access control in one place
   - Provides consistent repository access across the application
   - Separates business logic from data access

2. **Organization-Based Access Control**
   - Access is based on GitHub organizational boundaries
   - Users who have added PR Cat to their GitHub organizations can access those repositories
   - Repositories are always presented in their organizational context
   - User interfaces are built around organization selection first, then repositories

3. **Service Integration Plan**
   - Update all pages to use the RepositoryService instead of direct database queries
   - Remove duplicate implementation of repository queries
   - Standardize the organization-based access control across the application
   - Provide consistent user experience between settings and webhook configuration

4. **Architectural Benefits**
   - Single source of truth for repository access logic
   - Consistent error handling and logging
   - Easier to maintain and extend
   - Clear separation of concerns
   - Respect for GitHub's organizational boundaries

The repository service implements a layer of abstraction between the raw database queries and the application's business logic, making it easier to:
- Change the underlying database without affecting the rest of the application
- Implement complex access control rules in one place
- Test repository access logic in isolation
- Add caching or other optimizations at the service level

This architectural improvement addresses issues with duplicate code and inconsistent access patterns that were causing problems in the webhook configuration page.

## Implementation Details

### Turso Database Implementation

The Turso implementation will follow these specific steps:

1. **Database Setup and Management**
   - Use Turso Platform API to create and manage databases
   - Create separate database groups for development and production environments
   - Generate and securely store authentication tokens
   - Implement proper token rotation and security measures

2. **Schema Design and Management**
   - Create SQL scripts for table creation and schema updates
   - Implement custom migration system for tracking schema changes
   - Design optimized indices for common query patterns
   - Configure proper constraints and relationships

3. **Connection and Query Management**
   - Use Turso's Next.js integration for efficient connections
   - Implement connection pooling for optimal performance
   - Create parameterized queries to prevent SQL injection
   - Develop a structured query builder to simplify common operations

4. **Vector Capabilities**
   - Enable SQLite vector extensions
   - Create embedding storage schema
   - Implement similarity search functions
   - Optimize vector operations for performance

5. **Scale to Zero Support**
   - Design for Turso's scale-to-zero functionality
   - Implement proper connection handling for cold starts
   - Create retry mechanisms for connection failures
   - Optimize connection warm-up procedures

6. **Performance Monitoring**
   - Utilize Turso's usage statistics API
   - Track query performance and optimize slow queries
   - Monitor database size and growth
   - Implement query caching for frequently accessed data

7. **Backup and Recovery**
   - Configure point-in-time recovery options
   - Create regular backup procedures
   - Implement disaster recovery plans
   - Test recovery procedures periodically

### Database Schema

The core database tables should include:

- **Users**: User accounts and authentication
- **Organizations**: GitHub organizations
- **Repositories**: GitHub repositories with metadata
- **PullRequests**: PR data with metadata and categorization
- **Categories**: Investment area definitions and rules
- **Reviews**: PR review data and metrics
- **Settings**: User and organization settings
- **Recommendations**: Generated improvement recommendations

### Direct SQL Implementation

For optimal Turso database usage:

1. Use direct SQL queries instead of ORMs
2. Implement prepared statements for security
3. Use Turso's vector capabilities for semantic search
4. Create optimized indexes for common query patterns
5. Use database transactions for data consistency

### GitHub Integration

The GitHub integration requires:

1. OAuth authentication for user access
2. Organization and repository selection
3. Webhook configuration for real-time updates
4. API access for historical data collection
5. Permission scopes:
   - `repo` - For repository access
   - `read:org` - For organization data
   - `user:email` - For user identification

### AI Categorization Process

The AI categorization should:

1. Extract relevant text from PR (title, description, files changed)
2. Generate a structured prompt with context
3. Call AI service for categorization
4. Parse and validate response
5. Store categorization with confidence score
6. Allow manual overrides

### Vercel Resource Configuration

Optimize Vercel resources by:

1. Using Edge functions for lightweight operations
2. Implementing serverless functions for heavier processing
3. Setting up Cron jobs for periodic tasks
4. Using KV store for caching and job state
5. Configuring reasonable timeouts and memory limits

## Implementation Sequence

The adjusted implementation sequence based on current progress:

1. Complete database setup with direct SQL to Turso
2. Finish GitHub integration
3. Implement data collection and storage
4. Build AI processing pipeline
5. Connect UI to real data sources
6. Implement recommendations engine
7. Add search and filtering capabilities
8. Deploy with proper monitoring 

## Dashboard Data Integration Plan

Based on our analysis of the codebase, we've identified that the PR data collection via webhooks and AI categorization is working correctly. Now we need to connect our dashboard components to this real data. Here's the detailed implementation plan:

### 1. PR Activity Table Integration

The PR Activity Table component (`components/pr-activity-table.tsx`) currently uses mock data from a JSON file. We need to modify it to fetch real PR data from our database:

```typescript
// Updated useEffect in pr-activity-table.tsx
useEffect(() => {
  const fetchData = async () => {
    try {
      setLoading(true);
      // Fetch real PR data from the API
      const response = await fetch('/api/pull-requests/recent');
      if (!response.ok) {
        throw new Error('Failed to fetch recent pull requests');
      }
      const data = await response.json();
      setPullRequests(data);
    } catch (error) {
      console.error("Failed to load pull request data:", error);
    } finally {
      setLoading(false);
    }
  };

  fetchData();
}, []);
```

Create the corresponding API endpoint:

```typescript
// app/api/pull-requests/recent/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { getOrganizationPullRequests } from '@/lib/repositories';
import { RepositoryService } from '@/lib/services/repository-service';
import { auth } from '@/auth';

export async function GET(request: NextRequest) {
  try {
    const session = await auth();
    if (!session || !session.user) {
      return NextResponse.json({ error: 'Not authenticated' }, { status: 401 });
    }

    // Get the user's active organization
    const organizations = await RepositoryService.getUserOrganizations(session.user.id);
    if (!organizations || organizations.length === 0) {
      return NextResponse.json({ error: 'No organizations found' }, { status: 404 });
    }

    // For simplicity, use the first organization
    const orgId = organizations[0].id;

    // Get recent PRs from this organization
    const pullRequests = await getOrganizationPullRequests(orgId, {
      limit: 10,
      orderBy: 'created_at',
      orderDir: 'DESC'
    });

    // Transform the data to match the component's expected format
    const formattedPRs = await Promise.all(pullRequests.map(async pr => {
      // Get repository details
      const repo = await RepositoryService.getRepositoryById(pr.repository_id);
      
      // Get author details (this would be expanded in a real implementation)
      const author = { id: pr.author_id, name: 'Unknown' }; // You'd fetch the real name
      
      return {
        id: pr.id,
        title: pr.title,
        number: pr.number,
        developer: author,
        repository: {
          id: repo?.id || 0,
          name: repo?.name || 'Unknown'
        },
        status: pr.state,
        createdAt: pr.created_at,
        reviewStartedAt: '', // Would need to calculate from reviews
        mergedAt: pr.merged_at || '',
        deployedAt: '', // Not tracked yet
        reviewers: [], // Would need to fetch from reviews
        linesAdded: pr.additions || 0,
        linesRemoved: pr.deletions || 0,
        files: pr.changed_files || 0,
        commentCount: 0, // Would need to calculate
        approvalCount: 0, // Would need to calculate
        reviewThoroughness: 0, // Would need to calculate
        timeToFirstReview: 0, // Would need to calculate
        reviewTime: 0, // Would need to calculate
        cycleTime: calculateCycleTime(pr),
        qualityScore: 0, // Would need to calculate
        investmentArea: pr.category_id ? await getCategoryName(pr.category_id) : undefined
      };
    }));

    return NextResponse.json(formattedPRs);
  } catch (error) {
    console.error('Error fetching recent pull requests:', error);
    return NextResponse.json({ error: 'Failed to fetch pull requests' }, { status: 500 });
  }
}

// Helper function to calculate cycle time (implementation would depend on your definition)
function calculateCycleTime(pr) {
  // Example implementation - time from creation to merge in hours
  if (!pr.merged_at) return 0;
  
  const created = new Date(pr.created_at);
  const merged = new Date(pr.merged_at);
  return (merged.getTime() - created.getTime()) / (1000 * 60 * 60);
}

// Helper function to get category name
async function getCategoryName(categoryId) {
  // Implementation would fetch category name from database
  const category = await findCategoryById(categoryId);
  return category?.name || 'Uncategorized';
}
```

### 2. Investment Area Distribution Integration

The Investment Area Distribution component (`components/investment-area-distribution.tsx`) needs to be connected to real category data:

```typescript
// Updated InvestmentAreaDistribution component
export function InvestmentAreaDistribution() {
  const [data, setData] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const fetchData = async () => {
      try {
        setLoading(true);
        // Fetch category distribution data
        const response = await fetch('/api/pull-requests/category-distribution');
        if (!response.ok) {
          throw new Error('Failed to fetch category distribution');
        }
        const categoryData = await response.json();
        
        // Map to the format needed for the chart
        const formattedData = categoryData.map((item, index) => ({
          name: item.category_name || 'Uncategorized',
          value: item.count,
          color: getColorForIndex(index) // Helper function to assign colors
        }));
        
        setData(formattedData);
      } catch (error) {
        console.error("Failed to load category distribution:", error);
      } finally {
        setLoading(false);
      }
    };

    fetchData();
  }, []);

  // Rest of component remains similar, but uses the state data instead of hardcoded data
}

// Helper function to assign colors
function getColorForIndex(index) {
  const colors = [
    "#3b82f6", // Blue
    "#ef4444", // Red
    "#f97316", // Orange
    "#a855f7", // Purple
    "#14b8a6", // Teal
    "#eab308", // Yellow
    "#ec4899"  // Pink
  ];
  return colors[index % colors.length];
}
```

Create the corresponding API endpoint:

```typescript
// app/api/pull-requests/category-distribution/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { getPullRequestCountByCategory } from '@/lib/repositories';
import { RepositoryService } from '@/lib/services/repository-service';
import { auth } from '@/auth';

export async function GET(request: NextRequest) {
  try {
    const session = await auth();
    if (!session || !session.user) {
      return NextResponse.json({ error: 'Not authenticated' }, { status: 401 });
    }

    // Get the user's active organization
    const organizations = await RepositoryService.getUserOrganizations(session.user.id);
    if (!organizations || organizations.length === 0) {
      return NextResponse.json({ error: 'No organizations found' }, { status: 404 });
    }

    // For simplicity, use the first organization
    const orgId = organizations[0].id;

    // Get PR count by category
    const categoryDistribution = await getPullRequestCountByCategory(orgId);

    return NextResponse.json(categoryDistribution);
  } catch (error) {
    console.error('Error fetching category distribution:', error);
    return NextResponse.json({ error: 'Failed to fetch category distribution' }, { status: 500 });
  }
}
```

### 3. Engineering Metrics Integration

The Engineering Metrics component (`components/compact-engineering-metrics.tsx`) needs to be updated to use real data:

```typescript
// New API endpoint for time series metrics
// app/api/metrics/time-series/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { RepositoryService } from '@/lib/services/repository-service';
import { auth } from '@/auth';
import { 
  getRepositoryPullRequests, 
  getPullRequestReviews,
  getAveragePullRequestSize 
} from '@/lib/repositories';

export async function GET(request: NextRequest) {
  try {
    const session = await auth();
    if (!session || !session.user) {
      return NextResponse.json({ error: 'Not authenticated' }, { status: 401 });
    }

    // Get the user's organizations
    const organizations = await RepositoryService.getUserOrganizations(session.user.id);
    if (!organizations || organizations.length === 0) {
      return NextResponse.json({ error: 'No organizations found' }, { status: 404 });
    }

    // For simplicity, use the first organization
    const orgId = organizations[0].id;

    // Calculate time series data for the last 14 days
    const today = new Date();
    const startDate = new Date(today);
    startDate.setDate(startDate.getDate() - 14);

    const timeSeriesData = [];

    // For each day in the range
    for (let i = 0; i <= 14; i++) {
      const currentDate = new Date(startDate);
      currentDate.setDate(currentDate.getDate() + i);
      
      const dateStr = currentDate.toISOString().split('T')[0];
      const nextDate = new Date(currentDate);
      nextDate.setDate(nextDate.getDate() + 1);
      
      // Get PRs merged on this day
      const timeRange = {
        from: currentDate.toISOString(),
        to: nextDate.toISOString()
      };
      
      // Calculate metrics for this day
      // This is a simplified example - real implementation would be more sophisticated
      const mergedPRs = await getOrganizationPullRequests(orgId, {
        state: 'merged',
        timeRange
      });
      
      const prThroughput = mergedPRs.length;
      
      // Calculate average cycle time (time from creation to merge)
      let totalCycleTime = 0;
      let totalReviewTime = 0;
      
      for (const pr of mergedPRs) {
        if (pr.created_at && pr.merged_at) {
          const created = new Date(pr.created_at);
          const merged = new Date(pr.merged_at);
          totalCycleTime += (merged.getTime() - created.getTime()) / (1000 * 60 * 60);
          
          // Get reviews to calculate review time
          const reviews = await getPullRequestReviews(pr.id);
          if (reviews.length > 0) {
            const firstReview = reviews.sort((a, b) => 
              new Date(a.submitted_at).getTime() - new Date(b.submitted_at).getTime()
            )[0];
            
            const reviewStart = new Date(firstReview.submitted_at);
            totalReviewTime += (reviewStart.getTime() - created.getTime()) / (1000 * 60 * 60);
          }
        }
      }
      
      const cycleTime = mergedPRs.length > 0 ? totalCycleTime / mergedPRs.length : 0;
      const reviewTime = mergedPRs.length > 0 ? totalReviewTime / mergedPRs.length : 0;
      
      // Estimated coding hours (placeholder - would need a more sophisticated calculation)
      const sizeMetrics = await getAveragePullRequestSize(orgId, timeRange);
      const codingHours = sizeMetrics ? 
        (sizeMetrics.avg_additions + sizeMetrics.avg_deletions) / 100 : 0;
      
      timeSeriesData.push({
        date: dateStr,
        prThroughput,
        cycleTime,
        reviewTime,
        codingHours
      });
    }

    return NextResponse.json(timeSeriesData);
  } catch (error) {
    console.error('Error calculating time series metrics:', error);
    return NextResponse.json({ error: 'Failed to calculate metrics' }, { status: 500 });
  }
}
```

Then update the component to use this API:

```typescript
// Updated CompactEngineeringMetrics component
export function CompactEngineeringMetrics() {
  const [chartData, setChartData] = React.useState<TimeSeriesDataPoint[]>([]);
  const [loading, setLoading] = React.useState(true);

  React.useEffect(() => {
    const fetchData = async () => {
      try {
        // Call the real API endpoint
        const response = await fetch('/api/metrics/time-series');
        if (!response.ok) {
          throw new Error('Failed to fetch time series metrics');
        }
        const data = await response.json();
        setChartData(data);
      } catch (error) {
        console.error("Failed to load time series data:", error);
      } finally {
        setLoading(false);
      }
    };

    fetchData();
  }, []);

  // Rest of component remains similar
}
```

### 4. Implementation Sequence

To implement these dashboard data integrations, follow this sequence:

1. Implement the API endpoints:
   - First create `/api/pull-requests/recent`
   - Then create `/api/pull-requests/category-distribution`
   - Finally create `/api/metrics/time-series`

2. Update the components one by one:
   - Start with PR Activity Table as it's the most visible and useful
   - Then update Investment Area Distribution to show real category data
   - Finally update Engineering Metrics with real time series data

3. Add caching where appropriate:
   - Consider using Next.js data caching for expensive API calls
   - Cache time series data that doesn't change frequently
   - Implement incremental static regeneration for dashboard views

4. Add user context:
   - Allow users to select which organization to view
   - Add repository filtering to all views
   - Implement date range selection for metrics

By following this plan, you'll transform the static dashboard mockups into dynamic views that display real PR categorization data from your database. 